{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H1>Pattern similarities</H1>\n",
    "\n",
    "<P>We will compare similarities between the patterns in a network before (input) and after (output) the effect of inhibition.</P>\n",
    "\n",
    "<P> If patterns of activity are less similar after inhibition, we will have pattern separation</P>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# load necessary modules\n",
    "%pylab inline\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from inet.plots import plot_linear_fit\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0.11\n"
     ]
    }
   ],
   "source": [
    "from inet import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Definition of random pattern $\\boldsymbol{z}$</H2>\n",
    "\n",
    "<P>A memory random pattern $\\boldsymbol{z}$ is the representation of the activity of all the neurons in the network. It is a vector of lenght n, being n the total number of neurons in the network.</P>\n",
    "\n",
    "$\\boldsymbol{z}_i: i = \\{0, 1, \\cdots, n\\},$\n",
    "\n",
    "\n",
    "<P>The i-th element of the pattern is an independent random variable of probability a to be one when the neuron is active,  and zero if not (1-a). </P>\n",
    "\n",
    "\\begin{equation}\n",
    "    \\Pr(\\boldsymbol{z}_i) = \n",
    "        \\begin{cases}\n",
    "        1, & \\text{if} \\ \\ \\boldsymbol{z}_i < a,\\\\\n",
    "        0, & \\text{if} \\ \\ \\boldsymbol{z}_i \\geq 1-a\\\\\n",
    "        \\end{cases}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def randpattern(size, prob):\n",
    "    \"\"\"\n",
    "    Creates a pattern of activities (ones) with a given probability. \n",
    "    Activity is 1 if the cell is active, zero otherwise.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    size : ndarray\n",
    "           vector size\n",
    "    prob : float\n",
    "            probability of having ones\n",
    "    \"\"\"\n",
    "    z = np.zeros(size, dtype=int)\n",
    "    mysize = int(size*prob)\n",
    "\n",
    "    z[np.random.choice(size, mysize, replace=False)]=1 # without replacement. Thank you Clau!!!!\n",
    "    \n",
    "    return(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Vector norm</H2>\n",
    "\n",
    "The most commonly encountered vector norm (often simply called \"the norm\" of a vector, or sometimes the magnitude of a vector) is the L2-norm, given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\left\\| \\boldsymbol{z} \\right\\|_2 := \\sqrt{z_1^2 + \\cdots + z_n^2}.\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = randpattern(size=10, prob=0.5) # example for testing\n",
    "mycount = list()\n",
    "for _ in range(100):\n",
    "    mycount.append(np.count_nonzero(randpattern(10,.5)) )\n",
    "    \n",
    "np.mean(mycount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.2360679774997898"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(z, ord=2) #norm2 of a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4142135623730951"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm([1,1],2) # must be sqrt(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Definition of similarity</H2>\n",
    "\n",
    "It is the cosine of the normalized dot product of two vectors. It is equivalent to the Pearson correlation coefficient.\n",
    "\n",
    "$$\n",
    "\\text{similarity} = \\cos(\\theta) \n",
    "= {\\mathbf{a} \\cdot \\mathbf{b} \\over \\|\\mathbf{a}\\|_2 \\|\\mathbf{b}\\|_2} \n",
    "= \\frac{ \\sum\\limits_{i=1}^{n}{a_i  b_i} }{ \\sqrt{\\sum\\limits_{i=1}^{n}{a_i^2}}  \\sqrt{\\sum\\limits_{i=1}^{n}{b_i^2}} }    \n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def similarity(a, b):\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between samples in A and B.\n",
    "\n",
    "    Cosine similarity, or the cosine kernel, computes similarity as the\n",
    "    normalized dot product of A and B:\n",
    "\n",
    "     K(a, b) = <a, b> / (||a||*||b||)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : ndarray .\n",
    "\n",
    "    b : ndarray.\n",
    "\n",
    "    \"\"\"\n",
    "    # dot product is scalar product\n",
    "    return np.dot( a/np.linalg.norm(a), b/np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sim = list()\n",
    "for _ in range(1000):\n",
    "    a = randpattern(100,.5)\n",
    "    b = randpattern(100,.5)\n",
    "    sim.append(similarity(a, b))\n",
    "\n",
    "print(np.mean(sim)) # get this analytically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity([1,0,1],[0,1,0]) # must be zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2>Pattern separation</H2>\n",
    "\n",
    "It is the devation in the similarities between the input vectors and the output vectors. If both\n",
    "input and output vectors have the same similarity, then the relationship between their similarities is\n",
    "linear. Any positive deviation from the identity line when plotting similarities of input and output vectors will\n",
    "be because the output pattner are less similar than the input patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_pattern_separation(inputpattern, outputpattern, ax = None):\n",
    "    \"\"\"\n",
    "    input pattern: a list containing tuples of input patterns\n",
    "    outputpattern: a list containing tuples of outputpatterns\n",
    "    \n",
    "    Computes the linear regression of the similarity between paired patterns\n",
    "    and plot a line with the 95% confident intervals.\n",
    "    \n",
    "    Returns:\n",
    "    \n",
    "    pattern_completion: int\n",
    "        0 if no pattern completion.\n",
    "    \"\"\"\n",
    "    \n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    yval = np.array([similarity(x,y) for x,y in inputpattern])\n",
    "    xval = np.array([similarity(x,y) for x,y in outputpattern])\n",
    "    \n",
    "    supralinear = yval[yval>xval]\n",
    "    print(\"Proportion of separated patterns {:2.4f}\".format(len(supralinear)/len(xval)))\n",
    "    \n",
    "    xlin = np.linspace(0,1,100) # identity line\n",
    "    \n",
    "    ax.scatter(xval, yval, color='gray')\n",
    "    \n",
    "    ax.plot(xlin, xlin, '--', color='brown', alpha=.6)\n",
    "    ax.set_xlim(0,1), \n",
    "    ax.set_ylim(0,1)\n",
    "    ax.fill_between(xlin, 1, xlin, color='yellow', alpha=.1) # area of pattern comp.\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate 100 input patterns of 30% and 50% activity\n",
    "npatterns = 100\n",
    "inputpattern  = [(randpattern(1000, .3), randpattern(1000,.5)) for _ in range(npatterns)]\n",
    "len(inputpattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# there is no pattern separation of the inputs and outputs are the same\n",
    "plot_pattern_separation(inputpattern, inputpattern) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "I_network1 = randpattern(1000,.1) # 90% of neurons are active (are zeros)\n",
    "I = I_network1\n",
    "outpattern  = [(I*x, I*y) for x,y in inputpattern]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    " \n",
    "ax = plot_pattern_separation(inputpattern, outpattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
